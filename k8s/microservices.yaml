# Safety Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: safety
  namespace: ai-search
  labels:
    app: safety
spec:
  replicas: 2
  selector:
    matchLabels:
      app: safety
  template:
    metadata:
      labels:
        app: safety
    spec:
      containers:
      - name: safety
        image: ai-search/safety:latest
        ports:
        - containerPort: 8084
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: LOG_LEVEL
          value: "info"
        volumeMounts:
        - name: config-volume
          mountPath: /root/config.yaml
          subPath: config.yaml
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8084"
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8084"
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config-volume
        configMap:
          name: ai-search-config

---
apiVersion: v1
kind: Service
metadata:
  name: safety-service
  namespace: ai-search
spec:
  selector:
    app: safety
  ports:
  - port: 8084
    targetPort: 8084
  type: ClusterIP

---
# Search Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: search
  namespace: ai-search
  labels:
    app: search
spec:
  replicas: 2
  selector:
    matchLabels:
      app: search
  template:
    metadata:
      labels:
        app: search
    spec:
      containers:
      - name: search
        image: ai-search/search:latest
        ports:
        - containerPort: 8081
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: LOG_LEVEL
          value: "info"
        - name: GOOGLE_API_KEY
          valueFrom:
            secretKeyRef:
              name: google-api-secret
              key: api-key
              optional: true
        - name: GOOGLE_CX
          valueFrom:
            secretKeyRef:
              name: google-api-secret
              key: cx
              optional: true
        volumeMounts:
        - name: config-volume
          mountPath: /root/config.yaml
          subPath: config.yaml
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8081"
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8081"
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config-volume
        configMap:
          name: ai-search-config

---
apiVersion: v1
kind: Service
metadata:
  name: search-service
  namespace: ai-search
spec:
  selector:
    app: search
  ports:
  - port: 8081
    targetPort: 8081
  type: ClusterIP

---
# Tokenizer Service (CPU intensive)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tokenizer
  namespace: ai-search
  labels:
    app: tokenizer
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tokenizer
  template:
    metadata:
      labels:
        app: tokenizer
    spec:
      containers:
      - name: tokenizer
        image: ai-search/tokenizer:latest
        ports:
        - containerPort: 8082
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: LOG_LEVEL
          value: "info"
        volumeMounts:
        - name: config-volume
          mountPath: /root/config.yaml
          subPath: config.yaml
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8082"
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8082"
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config-volume
        configMap:
          name: ai-search-config

---
apiVersion: v1
kind: Service
metadata:
  name: tokenizer-service
  namespace: ai-search
spec:
  selector:
    app: tokenizer
  ports:
  - port: 8082
    targetPort: 8082
  type: ClusterIP

---
# Inference Service (GPU intensive)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference
  namespace: ai-search
  labels:
    app: inference
spec:
  replicas: 2
  selector:
    matchLabels:
      app: inference
  template:
    metadata:
      labels:
        app: inference
    spec:
      containers:
      - name: inference
        image: ai-search/inference:latest
        ports:
        - containerPort: 8083
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: LOG_LEVEL
          value: "info"
        volumeMounts:
        - name: config-volume
          mountPath: /root/config.yaml
          subPath: config.yaml
        resources:
          requests:
            memory: "1Gi"
            cpu: "1000m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8083"
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - "nc -z localhost 8083"
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config-volume
        configMap:
          name: ai-search-config

---
apiVersion: v1
kind: Service
metadata:
  name: inference-service
  namespace: ai-search
spec:
  selector:
    app: inference
  ports:
  - port: 8083
    targetPort: 8083
  type: ClusterIP

---
# Gateway Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gateway
  namespace: ai-search
  labels:
    app: gateway
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gateway
  template:
    metadata:
      labels:
        app: gateway
    spec:
      containers:
      - name: gateway
        image: ai-search/gateway:latest
        ports:
        - containerPort: 8080
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: LOG_LEVEL
          value: "info"
        - name: GOOGLE_API_KEY
          valueFrom:
            secretKeyRef:
              name: google-api-secret
              key: api-key
              optional: true
        - name: GOOGLE_CX
          valueFrom:
            secretKeyRef:
              name: google-api-secret
              key: cx
              optional: true
        volumeMounts:
        - name: config-volume
          mountPath: /root/config.yaml
          subPath: config.yaml
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config-volume
        configMap:
          name: ai-search-config

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-orchestrator
  namespace: ai-search
spec:
  replicas: 2
  selector:
    matchLabels:
      app: llm-orchestrator
  template:
    metadata:
      labels:
        app: llm-orchestrator
    spec:
      containers:
      - name: llm-orchestrator
        image: ai-search-service:latest
        command: ["./llm"]
        ports:
        - containerPort: 8085
        env:
        - name: REDIS_HOST
          value: "redis"
        - name: TOKENIZER_HOST
          value: "tokenizer"
        - name: INFERENCE_HOST
          value: "inference"
        - name: LLM_MAX_WORKERS
          value: "10"
        - name: LLM_MAX_QUEUE_SIZE
          value: "10000"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8085
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8085
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: llm-orchestrator
  namespace: ai-search
spec:
  selector:
    app: llm-orchestrator
  ports:
  - port: 8085
    targetPort: 8085
  type: ClusterIP

---
apiVersion: v1
kind: Service
metadata:
  name: gateway-service
  namespace: ai-search
spec:
  selector:
    app: gateway
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer 