syntax = "proto3";

package search;

option go_package = "./proto";

// Search service definitions
service SearchService {
  rpc Search(SearchRequest) returns (SearchResponse);
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}

// Enterprise Tokenizer service definitions
service TokenizerService {
  rpc Tokenize(TokenizeRequest) returns (TokenizeResponse);
  rpc BatchTokenize(BatchTokenizeRequest) returns (BatchTokenizeResponse);
  rpc GetVocabularyInfo(VocabularyInfoRequest) returns (VocabularyInfoResponse);
  
  // Detokenization methods (industry standard)
  rpc Detokenize(DetokenizeRequest) returns (DetokenizeResponse);
  rpc BatchDetokenize(BatchDetokenizeRequest) returns (BatchDetokenizeResponse);
  
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}


// Inference service definitions
service InferenceService {
  rpc Summarize(SummarizeRequest) returns (SummarizeResponse);
  rpc SummarizeStream(SummarizeRequest) returns (stream SummarizeStreamResponse);
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}

// Safety service definitions
service SafetyService {
  rpc ValidateInput(ValidateInputRequest) returns (ValidateInputResponse);
  rpc SanitizeOutput(SanitizeOutputRequest) returns (SanitizeOutputResponse);
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}

// LLM Orchestrator service definitions
service LLMOrchestratorService {
  rpc ProcessRequest(LLMRequest) returns (LLMResponse);
  rpc StreamRequest(LLMRequest) returns (stream LLMStreamResponse);
  rpc GetStatus(LLMStatusRequest) returns (LLMStatusResponse);
  rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);
}

// Common messages
message HealthCheckRequest {}

message HealthCheckResponse {
  string status = 1;
  string service = 2;
  int64 timestamp = 3;
}

// Search messages
message SearchRequest {
  string query = 1;
  bool safe_search = 2;
  int32 num_results = 3;
}

message SearchResponse {
  repeated SearchResult results = 1;
  string query = 2;
  bool success = 3;
  string error = 4;
}

message SearchResult {
  string title = 1;
  string url = 2;
  string snippet = 3;
  string display_url = 4;
}


// Enterprise Tokenizer messages
message TokenizeRequest {
  string text = 1;
  string model_name = 2;        // e.g., "gpt-4", "llama3.2"
  int32 max_tokens = 3;         // truncation limit
  bool include_special_tokens = 4;
  string request_id = 5;        // for tracking/caching
}

message TokenizeResponse {
  repeated int32 token_ids = 1;
  repeated string token_strings = 2;  // human-readable tokens
  int32 token_count = 3;
  string truncated_text = 4;    // if truncation occurred
  bool was_truncated = 5;
  string model_used = 6;
  float processing_time_ms = 7; // performance metrics
  string cache_status = 8;      // "hit", "miss", "bypassed"
  bool success = 9;
  string error = 10;
}

message BatchTokenizeRequest {
  repeated TokenizeRequest requests = 1;
  int32 batch_size = 2;
}

message BatchTokenizeResponse {
  repeated TokenizeResponse responses = 1;
  float total_processing_time_ms = 2;
  int32 cache_hits = 3;
  int32 cache_misses = 4;
}

message VocabularyInfoRequest {
  string model_name = 1;
}

message VocabularyInfoResponse {
  int32 vocab_size = 1;
  repeated string special_tokens = 2;
  string encoding_name = 3;      // e.g., "cl100k_base"
  string model_name = 4;
}

// Detokenization messages (industry standard: token IDs -> text)
message DetokenizeRequest {
  repeated int32 token_ids = 1;
  string model_name = 2;         // must match tokenization model
  bool skip_special_tokens = 3;  // remove <s>, </s>, etc.
  string request_id = 4;         // for tracking/caching
}

message DetokenizeResponse {
  string text = 1;               // reconstructed text
  int32 token_count = 2;         // number of tokens processed
  string model_used = 3;
  float processing_time_ms = 4;  // performance metrics
  string cache_status = 5;       // "hit", "miss", "bypassed"
  bool success = 6;
  string error = 7;
}

message BatchDetokenizeRequest {
  repeated DetokenizeRequest requests = 1;
  int32 batch_size = 2;
}

message BatchDetokenizeResponse {
  repeated DetokenizeResponse responses = 1;
  float total_processing_time_ms = 2;
  int32 cache_hits = 3;
  int32 cache_misses = 4;
}

// Enhanced Inference messages (Industry Standard)
message SummarizeRequest {
  repeated int32 token_ids = 1;     // PRIMARY: from tokenizer service
  string model_name = 2;           // which model/tokenizer was used
  bool streaming = 3;
  int32 max_length = 4;
  string request_id = 5;           // for correlation
  string original_text = 6;        // FALLBACK ONLY: for non-tokenized requests
}

message SummarizeResponse {
  string summary = 1;
  bool success = 2;
  string error = 3;
  int32 tokens_used = 4;
  float confidence = 5;
  repeated int32 generated_token_ids = 6;  // TOKEN-NATIVE: Generated tokens for detokenization
}

message SummarizeStreamResponse {
  string token = 1;
  bool is_final = 2;
  string error = 3;
  int32 position = 4;
  int32 generated_token_id = 5;  // TOKEN-NATIVE: Token ID for streaming detokenization
}

// Safety messages
message ValidateInputRequest {
  string text = 1;
  string client_ip = 2;
  bool safe_search = 3;
}

message ValidateInputResponse {
  bool is_safe = 1;
  string sanitized_text = 2;
  repeated string warnings = 3;
  string error = 4;
}

message SanitizeOutputRequest {
  string text = 1;
}

message SanitizeOutputResponse {
  string sanitized_text = 1;
  repeated string warnings = 2;
  string error = 3;
}

// LLM Orchestrator messages
message LLMRequest {
  string id = 1;
  string text = 2;
  int32 max_tokens = 3;
  bool stream = 4;
  int64 created_at = 5;
}

message LLMResponse {
  string id = 1;
  repeated string tokens = 2;
  string summary = 3;
  string error = 4;
  bool complete = 5;
}

message LLMStatusRequest {
  string request_id = 1;
}

message LLMStatusResponse {
  string request_id = 1;
  string status = 2; // pending, processing, completed, failed
  int32 queue_position = 3;
  int32 estimated_wait_time = 4; // seconds
  string error = 5;
}

message LLMStreamResponse {
  string id = 1;
  string token = 2;
  bool is_final = 3;
  string error = 4;
  int32 position = 5;
} 